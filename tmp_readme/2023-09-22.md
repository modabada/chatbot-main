- LSTM 레이어
	- model(img) 의 결과를 2군데에 넣어 하나는 출력, 하나는 내부에 돌림
- 게이트 순환 신경망(GRU)
	- LSTM 보다 구조가 간단하며 게이트 메커니즘이 적용된 RNN 프레임워크
	- 결과는 비슷하나 훈련시간이 짧다고 하는듯
- 양방향 RNN
	- 일반적인 시계열 데이터는 이전의 데이터가 이후 결과에 영향을 주는데,
	  양방향 RNN, bidirectional 은 이후의 데이터가 이전의 결과에도 영향을 주게 함
	- 모델 구조로는 메모리셀 2개를 이용해 계산함
		- 하나는 이전 시점의 은닉 상태를 받아 현제 은닉 상태를 계산
		- 하나는 다음 시점의 은닉 상태를 받아 현제 은닉 상태를 계산
		- 이 모두를 출력층에서 값을 예측하는데 사용함
		- RNN 이면 상관없고, 따라서 내가 해본 LSTM 이나 GRU 에도 적용 가능
	- biLSTM 구현
	  ``` python
	  # in SL000
	  self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,

            # 제일 중요한 차이인데 이거 한줄이 다임 ㅇㅇ
            bidirectional=True,
            batch_first=True,
        )
	  ```
- 성능 최적화
	- 임시 데이터를 넣어 데이터셋 개수 불리기
	- 적절한 알고리즘을 선택해 성능 최적화
	- 하이퍼 파라미터를 변경하며 성능 최적화
		- 가중치, 학습률, 활성화 함수, 배치와 에포크 등등
	- 2개의 모델을 섞어 사용해 성능 최적화(앙상블)
	- 하드웨어(GPU) 로 성능 최적화...인가? 학습시간 단축 아닌가?
	- 하이퍼 파라미터를 이용한 성능 최적화(2)
		- 배치 정규화
			- 데이터 범위를 사용자가 원하는 범위로 제한하는것을 의미
			- 보통은 0~1 사이로, 데이터의 평균을 0.5 가 되는것을 목표로 한다
		- 규제화
			- 모델 복잡도를 줄이기 위해 제한을 두는 것
			- 예시
				- 드롭아웃
				- 조기종료
		- 표준화
			- 데이터의 평균을 0, 표준편차를 1 의 형태로 만드는 방법
			- 다른 표현으로 스칼라, z-스코어 정규화 등으로 표현
		- 배치 정규화
			- 초기값 튜닝, 학습률, 손실함수 등을 조정..? remind 필요
		- 드롭아웃을 이용한 성능 최적화
			- 
- 수업 외
- 라마
	- 자연어 처리 오픈소스 모델중 가장 잘 나온 모델이라내요
- 채팅 프로그램 트랜드
	- 멀티 모달
		- 이미지와 텍스트를 함께 학습하여 만드는 AI
			- ex: (사진 전송 후) 이 동물의 이름은 무엇인가요?
				-> 얼룩말 이라는 결과 도출 유도
			- 이미지 뿐만이 아니라 음성파일, 영상 등에 대해서도 가능
			- 